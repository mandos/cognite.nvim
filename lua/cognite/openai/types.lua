local Struct = require("cognite.types.struct")

---@class CompletionObject
---@field id string
---@field object string
---@field created string
---@field choices Choice[]
---@field usage Usage
local Response = {}

---@class Choice
---@field index number
---@field massage Message|nil should be present if delta is not
---@field delta Message|nil should be present if message is not
---@field finish_reason string
local Choice = {}

---@class Usage
---@field prompt_tokens number
---@field completion_tokens number
---@field total_tokens number
local Usage = {}

---@class Message
---@field role string
---@field content string|nil
---@field function_call FunctionCall|nil
---@field name string|nil only for Request
local Message = Struct("Message", {
	role = "string",
	content = "string",
	-- function_call = "FunctionCall",
	name = "string",
})

---@class FunctionCall
---@field name string
---@field arguments string
local FunctionCall = {}

---@class CompletionChunk
---@field id string
---@field object string
---@field created string
---@field choices Choice[]
---@field model number
local CompletionChunk = {}

---@class OpenAIModel
---@field model string ID of the model to use. See the model endpoint compatibility table for details on which models work with the Chat API.
---@field temperature number|nil default 1
---@field top_p number|nil default 1
---@field n number|nil default 1
---@field presence_penalty number|nil default 0
---@field frequency_penalty number|nil default 0; Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

---@class Request
---@field messages Message[] A list of messages comprising the conversation so far.
---@field functions table[string] A list of functions the model may generate JSON inputs for.
---@field function_call string|nil Controls how the model responds to function calls. "none" means the model does not call a function, and responds to the end-user. "auto" means the model can pick between an end-user or calling a function. Specifying a particular function via {"name":\ "my_function"} forces the model to call that function. "none" is the default when no functions are present. "auto" is the default if functions are present.
---@field stream boolean|nil default false
---@field stop string[]|nil default nil
---@field logit_bias table[string]|nil default nil; Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
---@field user string|nil default nil A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
local Request = Struct("Request", {
	model = "string",
	messages = "table",
	-- temperature = 1,
	-- top_p = 1,
	-- n = 1,
	-- stream = false,
	-- stop = nil,
	-- presence_penalty = 0,
	-- frequency_penalty = 0,
	-- ---@diagnostic disable-next-line: assign-type-mismatch
	-- logit_bias = nil,
})

return {
	Response = Response,
	Choice = Choice,
	Usage = Usage,
	Message = Message,
	FunctionCall = FunctionCall,
	CompletionChunk = CompletionChunk,
	Request = Request,
}
